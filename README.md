# ğŸ§¬ Drug Response Predictor

This project applies supervised machine learning models to classify patient responses to various drug treatments.  
It uses Decision Trees, Random Forests, and visualization tools to explore and evaluate model performance.

âœ¨ Why I Made This
This project was created to demonstrate my hands-on ability to build, train, and evaluate a machine learning model in a biomedical context â€” including tasks often required for junior data science roles in healthcare, bioinformatics, or scientific computing.

It reflects essential capabilities such as:

Writing Python code for data pipelines and model workflows

Using ML frameworks like Scikit-Learn and Pandas

Interpreting clinical-style datasets with numeric and categorical features

Evaluating accuracy and visualizing prediction outputs

Delivering reproducible, annotated Colab notebooks that communicate the work clearly


## ğŸ” Key Features
- Built with Python, pandas, scikit-learn, matplotlib
- Trains and compares multiple classification models
- Designed for healthcare and bioinformatics applications


# ğŸ§ª Drug Response Predictor

This notebook builds a machine learning model to predict drug response based on features in a biomedical dataset. It walks through:

- Data loading and preprocessing
- Label encoding of categorical features
- Model training using Random Forest
- Accuracy evaluation and confusion matrix analysis

Useful for bioinformatics, ML beginners, and healthcare AI workflows.
## ğŸ“„ Notebook
[drug_response_predictor.ipynb](drug_response_predictor.ipynb)

## â–¶ï¸ Run in Colab
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Loretta991/Drug-Response-Predictor/blob/main/drug_response_predictor.ipynb)


## ğŸ” Feature Importance Visualization

ğŸ§¬ Feature Importance Visualization (Random Forest)
This notebook highlights which input features had the strongest impact on a trained Random Forest classifier â€” using a clean, colorful bar chart to show relative weights.

Useful for bioinformatics, ML beginners, and healthcare AI workflows

Shows how model interpretability can guide future drug response modeling or clinical decision-making

Great for learners who want to visually understand how different variables influence model predictions

ğŸ“Š Includes:

Dummy drug response dataset

Feature engineering & training

Weighted bar chart using Seaborn & Matplotlib

## ğŸ“„ Notebook
[drug_response_predictor.ipynb](Feature_Importance_Visualization.ipynb)

â–¶ï¸ Run in Colab:

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Loretta991/Drug-Response-Predictor/blob/main/Feature_Importance_Visualization.ipynb)

---
## ğŸ‘€ Return to Projects  
[![Return to GitHub Projects](https://img.shields.io/badge/GitHub-Return_to_Projects-blue?logo=github)](https://github.com/Loretta991)

## ğŸ‘¤ Return to LinkedIn  
[![LinkedIn](https://img.shields.io/badge/Return%20to%20LinkedIn-Profile-blue?logo=linkedin)](https://www.linkedin.com/in/elle-grey-8a9307299/)

